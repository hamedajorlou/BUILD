{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import json\n",
    "import dag_utils as utils\n",
    "from Baselines import Nonneg_dagma, MetMulDagma\n",
    "from Baselines import colide_ev\n",
    "from Baselines import DAGMA_linear\n",
    "from Baselines import notears_linear\n",
    "from BUILD import BUILD\n",
    "from utils import *\n",
    "PATH = './results/samples/'\n",
    "SAVE = True \n",
    "SEED = 10\n",
    "N_CPUS = os.cpu_count() \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _to_jsonable(obj):\n",
    "    \"\"\"Recursively convert objects to JSON-serializable forms.\"\"\"\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "\n",
    "    # basic types\n",
    "    if obj is None or isinstance(obj, (bool, int, float, str)):\n",
    "        # cast numpy scalars to Python\n",
    "        if isinstance(obj, (np.bool_, np.integer, np.floating)):\n",
    "            return obj.item()\n",
    "        return obj\n",
    "\n",
    "    # numpy arrays -> lists (careful for huge arrays: we won't dump arrays here)\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "\n",
    "    # tuples -> lists\n",
    "    if isinstance(obj, tuple):\n",
    "        return [_to_jsonable(x) for x in obj]\n",
    "\n",
    "    # lists\n",
    "    if isinstance(obj, list):\n",
    "        return [_to_jsonable(x) for x in obj]\n",
    "\n",
    "    # dicts\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _to_jsonable(v) for k, v in obj.items()}\n",
    "\n",
    "    # Path\n",
    "    if isinstance(obj, Path):\n",
    "        return str(obj)\n",
    "\n",
    "    # dataclasses\n",
    "    try:\n",
    "        from dataclasses import is_dataclass, asdict\n",
    "        if is_dataclass(obj):\n",
    "            return _to_jsonable(asdict(obj))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # callables (functions/classes)\n",
    "    if callable(obj):\n",
    "        # try to capture module + name; fall back to repr\n",
    "        name = getattr(obj, \"__name__\", obj.__class__.__name__)\n",
    "        mod  = getattr(obj, \"__module__\", None)\n",
    "        return f\"{mod+'.' if mod else ''}{name}\"\n",
    "\n",
    "    # objects with __dict__\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        return _to_jsonable(vars(obj))\n",
    "\n",
    "    # fallback\n",
    "    return repr(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import os, json, math, uuid, shutil, datetime as dt\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "from typing import Callable, Dict, Any, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from Baselines import GOLEM_Torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_lambda_value(n_nodes: int, n_samples: int, times: float = 1.0) -> float:\n",
    "    \"\"\"Common λ heuristic: sqrt(log p / n) scaled by `times`.\"\"\"\n",
    "    return math.sqrt(max(1e-12, np.log(max(2, n_nodes))) / max(2, n_samples)) * times\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BaselineSpec:\n",
    "    model: Any\n",
    "    init: Dict[str, Any] = field(default_factory=dict)\n",
    "    args: Dict[str, Any] = field(default_factory=dict)\n",
    "    name: str = \"baseline\"\n",
    "    standardize: bool = False\n",
    "    adapt_lambda: bool = False\n",
    "    topo_transpose: bool = False\n",
    "    is_topogreedy_refresh: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    n_graphs: int\n",
    "    n_nodes: int\n",
    "    n_samples_list: List[int]\n",
    "    edge_threshold: float\n",
    "    data_params: Dict[str, Any]\n",
    "    baselines: List[BaselineSpec]\n",
    "    out_dir: str = \"./exp_results\"\n",
    "    run_tag: Optional[str] = None\n",
    "    save_intermediate: bool = True\n",
    "    seed_offset: int = 0 \n",
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, cfg: ExperimentConfig):\n",
    "        self.cfg = cfg\n",
    "        self.run_id = cfg.run_tag or dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"_\" + uuid.uuid4().hex[:6]\n",
    "        self.out_root = Path(cfg.out_dir) / self.run_id\n",
    "        self.out_root.mkdir(parents=True, exist_ok=True)\n",
    "        self._save_manifest()\n",
    "\n",
    "    def run(self, verbose: bool = True):\n",
    "\n",
    "        B = len(self.cfg.baselines)\n",
    "        S = len(self.cfg.n_samples_list)\n",
    "        N = self.cfg.n_nodes\n",
    "        G = self.cfg.n_graphs\n",
    "\n",
    "        # Metrics tensors: (G, S, B)\n",
    "        shd = np.zeros((G, S, B))\n",
    "        tpr = np.zeros((G, S, B))\n",
    "        fdr = np.zeros((G, S, B))\n",
    "        fscore = np.zeros((G, S, B))\n",
    "        err = np.zeros((G, S, B))\n",
    "        runtime = np.zeros((G, S, B))\n",
    "        dag_count = np.zeros((G, S, B))\n",
    "        theta_diff = np.zeros((G, S, B))\n",
    "\n",
    "        W_est_all = np.zeros((G, S, B, N, N))\n",
    "        Theta_est_all = np.zeros((G, S, B, N, N))\n",
    "\n",
    "        for g in range(G):\n",
    "            if verbose:\n",
    "                print(f\"\\n=== Graph {g+1}/{G} ===\")\n",
    "\n",
    "            graph_seed = self.cfg.seed_offset + g\n",
    "            data_p = dict(self.cfg.data_params)\n",
    "            data_p[\"n_nodes\"] = self.cfg.n_nodes\n",
    "\n",
    "            W_true_cache = None\n",
    "            Theta_true_cache = None\n",
    "\n",
    "            for si, n_samples in enumerate(self.cfg.n_samples_list):\n",
    "                data_p_this = dict(data_p)\n",
    "                data_p_this[\"n_samples\"] = int(n_samples)\n",
    "\n",
    "                # simulate SEM\n",
    "                W_true, _, X, Theta_true = utils.simulate_sem(**data_p_this)\n",
    "\n",
    "                W_true_cache = W_true\n",
    "                Theta_true_cache = Theta_true\n",
    "\n",
    "                X_std = utils.standarize(X) if data_p_this.get(\"standarize\", False) else X\n",
    "                W_true_bin = utils.to_bin(W_true, self.cfg.edge_threshold)\n",
    "                norm_W_true = np.linalg.norm(W_true)\n",
    "                # emp_cov = (X_std.T @ X_std) / float(X_std.shape[0])\n",
    "                emp_cov = np.cov(X_std, rowvar = False)\n",
    "                print(f\"cond: {np.linalg.cond(Theta_true)}\")\n",
    "                if verbose:\n",
    "                    print(f\"- samples={n_samples}, edges≈{np.count_nonzero(W_true_bin)}\")\n",
    "\n",
    "                for bi, base in enumerate(self.cfg.baselines):\n",
    "                    X_in = X_std if base.standardize else X\n",
    "                    args_call = dict(base.args)\n",
    "\n",
    "                    # adaptive λ scheduling\n",
    "                    if base.adapt_lambda:\n",
    "                        if \"lamb\" in args_call:\n",
    "                            args_call[\"lamb\"] = get_lambda_value(self.cfg.n_nodes, n_samples, args_call[\"lamb\"])\n",
    "                        if \"lambda1\" in args_call:\n",
    "                            args_call[\"lambda1\"] = get_lambda_value(self.cfg.n_nodes, n_samples, args_call[\"lambda1\"])\n",
    "\n",
    "                    t0 = perf_counter()\n",
    "                    W_est, Theta_est = self._run_one_baseline(\n",
    "                        base=base,\n",
    "                        X=X_in,\n",
    "                        X_std=X_std,\n",
    "                        emp_cov=emp_cov,\n",
    "                        edge_thr=self.cfg.edge_threshold\n",
    "                    )\n",
    "                    t1 = perf_counter()\n",
    "                    \n",
    "\n",
    "                    if np.isnan(W_est).any():\n",
    "                        W_est = np.zeros_like(W_est)\n",
    "                        W_bin = np.zeros_like(W_est)\n",
    "                    else:\n",
    "                        W_bin = utils.to_bin(W_est, self.cfg.edge_threshold)\n",
    "\n",
    "                    if base.topo_transpose:\n",
    "                        W_est = W_est.T\n",
    "                        W_bin = W_bin.T\n",
    "\n",
    "                    # ---------- metrics ----------\n",
    "                    shd[g, si, bi], tpr[g, si, bi], fdr[g, si, bi] = utils.count_accuracy(W_true_bin, W_bin)\n",
    "                    fscore[g, si, bi] = f1_score(W_true_bin.flatten(), W_bin.flatten())\n",
    "                    err[g, si, bi] = utils.compute_norm_sq_err(W_true, W_est, norm_W_true)\n",
    "                    runtime[g, si, bi] = (t1 - t0)\n",
    "                    dag_count[g, si, bi] = 1.0 if utils.is_dag(W_bin) else 0.0\n",
    "\n",
    "                    if Theta_est is None:\n",
    "                        theta_diff[g, si, bi] = 0.0\n",
    "                    else:\n",
    "\n",
    "                        Theta_norm = np.linalg.norm(Theta_true, \"fro\")\n",
    "                        theta_diff[g, si, bi] = utils.compute_norm_sq_err(Theta_true, Theta_est, Theta_norm)\n",
    "\n",
    "                    # store estimates\n",
    "                    W_est_all[g, si, bi] = W_est\n",
    "                    if Theta_est is not None:\n",
    "                        Theta_est_all[g, si, bi] = Theta_est\n",
    "\n",
    "                    if verbose:\n",
    "                        print(f\"  · {base.name:<18s} | SHD {shd[g,si,bi]:.1f} | F1 {fscore[g,si,bi]:.3f} | \"\n",
    "                              f\"ΘΔ {theta_diff[g,si,bi]:.3f} | {runtime[g,si,bi]:.2f}s\")\n",
    "\n",
    "                if self.cfg.save_intermediate:\n",
    "                    data = self._save_block(\n",
    "                        g=g, si=si,\n",
    "                        W_true=W_true, Theta_true=Theta_true,\n",
    "                        W_est_all=W_est_all[g, si],\n",
    "                        Theta_est_all=Theta_est_all[g, si],\n",
    "                        shd=shd[g, si], tpr=tpr[g, si], fdr=fdr[g, si],\n",
    "                        f1=fscore[g, si], err=err[g, si], rt=runtime[g, si],\n",
    "                        dags=dag_count[g, si], theta_diff=theta_diff[g, si]\n",
    "                    )\n",
    "\n",
    "        final = dict(\n",
    "            shd=shd, tpr=tpr, fdr=fdr, f1=fscore, err=err,\n",
    "            runtime=runtime, dag_count=dag_count, theta_diff=theta_diff,\n",
    "            W_est_all=W_est_all, Theta_est_all=Theta_est_all\n",
    "        )\n",
    "        np.savez_compressed(self.out_root / \"final_results.npz\", **final)\n",
    "        if verbose:\n",
    "            print(f\"\\nSaved results to: {self.out_root}\")\n",
    "\n",
    "        return final, data\n",
    "\n",
    "    def _run_one_baseline(\n",
    "        self,\n",
    "        base: BaselineSpec,\n",
    "        X: np.ndarray,\n",
    "        X_std: np.ndarray,\n",
    "        emp_cov: np.ndarray,\n",
    "        edge_thr: float\n",
    "    ) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "\n",
    "        if callable(base.model) and not hasattr(base.model, \"fit\"):\n",
    "            # handle TopoGreedy_refresh function signature:\n",
    "            if base.is_topogreedy_refresh:\n",
    "                out = base.model(X, emp_cov, **base.args)\n",
    "                W_est = out.get(\"A_est\", None)\n",
    "                Theta_est = out.get(\"prec\", None)\n",
    "                if W_est is None:\n",
    "                    W_est = np.zeros((X.shape[1], X.shape[1]))\n",
    "                return W_est, Theta_est\n",
    "            else:\n",
    "                W_est = base.model(X, **base.args)\n",
    "                return W_est, None\n",
    "\n",
    "        model = base.model(**base.init) if base.init else base.model()\n",
    "        model.fit(X, **base.args)\n",
    "\n",
    "        W_est = getattr(model, \"W_est\", None)\n",
    "        if W_est is None:\n",
    "            W_est = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "        Theta_est = None\n",
    "        if hasattr(model, \"Theta_est\"):\n",
    "            Theta_est = getattr(model, \"Theta_est\")\n",
    "        elif hasattr(model, \"prec\"):\n",
    "            Theta_est = getattr(model, \"prec\")\n",
    "\n",
    "        return W_est, Theta_est\n",
    "\n",
    "    def _save_manifest(self):\n",
    "        sanitized_cfg = {\n",
    "            \"n_graphs\": self.cfg.n_graphs,\n",
    "            \"n_nodes\": self.cfg.n_nodes,\n",
    "            \"n_samples_list\": list(self.cfg.n_samples_list),\n",
    "            \"edge_threshold\": self.cfg.edge_threshold,\n",
    "            \"data_params\": _to_jsonable(self.cfg.data_params),\n",
    "            \"baselines\": [\n",
    "                {\n",
    "                    \"name\": b.name,\n",
    "                    \"model\": _to_jsonable(b.model),          \n",
    "                    \"init\": _to_jsonable(b.init),\n",
    "                    \"args\": _to_jsonable(b.args),\n",
    "                    \"standardize\": b.standardize,\n",
    "                    \"adapt_lambda\": b.adapt_lambda,\n",
    "                    \"topo_transpose\": b.topo_transpose,\n",
    "                    \"is_topogreedy_refresh\": b.is_topogreedy_refresh,\n",
    "                }\n",
    "                for b in self.cfg.baselines\n",
    "            ],\n",
    "            \"out_dir\": str(self.cfg.out_dir),\n",
    "            \"run_tag\": self.cfg.run_tag,\n",
    "            \"save_intermediate\": self.cfg.save_intermediate,\n",
    "            \"seed_offset\": self.cfg.seed_offset,\n",
    "        }\n",
    "\n",
    "        manifest = {\n",
    "            \"run_id\": self.run_id,\n",
    "            \"created_at\": dt.datetime.now().isoformat(),\n",
    "            \"config\": sanitized_cfg,\n",
    "            \"python\": {\"numpy_version\": np.__version__},\n",
    "        }\n",
    "\n",
    "        (self.out_root / \"config.json\").write_text(json.dumps(_to_jsonable(manifest), indent=2))\n",
    "\n",
    "    def _save_block(\n",
    "        self, g: int, si: int,\n",
    "        W_true: np.ndarray, Theta_true: np.ndarray,\n",
    "        W_est_all: np.ndarray,\n",
    "        Theta_est_all: np.ndarray,\n",
    "        shd: np.ndarray, tpr: np.ndarray, fdr: np.ndarray,\n",
    "        f1: np.ndarray, err: np.ndarray, rt: np.ndarray,\n",
    "        dags: np.ndarray, theta_diff: np.ndarray\n",
    "    ):\n",
    "        sub = self.out_root / f\"graph_{g:03d}\" / f\"samples_{self.cfg.n_samples_list[si]}\"\n",
    "        sub.mkdir(parents=True, exist_ok=True)\n",
    "        filename = sub / \"block.npz\"\n",
    "        np.savez_compressed(\n",
    "            filename,\n",
    "            W_true=W_true, Theta_true=Theta_true,\n",
    "            W_est_all=W_est_all, Theta_est_all=Theta_est_all,\n",
    "            shd=shd, tpr=tpr, fdr=fdr, f1=f1, err=err, runtime=rt,\n",
    "            dag_count=dags, theta_diff=theta_diff\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'filename': str(filename),\n",
    "            'W_true': W_true,\n",
    "            'Theta_true': Theta_true,\n",
    "            'W_est_all': W_est_all,\n",
    "            'Theta_est_all': Theta_est_all,\n",
    "            'shd': shd,\n",
    "            'tpr': tpr,\n",
    "            'fdr': fdr,\n",
    "            'f1': f1,\n",
    "            'err': err,\n",
    "            'runtime': rt,\n",
    "            'dag_count': dags,\n",
    "            'theta_diff': theta_diff\n",
    "        }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
